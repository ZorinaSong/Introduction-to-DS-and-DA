{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66aefc8a",
   "metadata": {},
   "source": [
    "# MIE 1624 - Group 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83127048",
   "metadata": {},
   "source": [
    "# Part 1: Extract data about tweets from Twitter API by using Tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686e27a",
   "metadata": {},
   "source": [
    "## 1. Setting up your Twitter Developers Account\n",
    "\n",
    "1. In order to use the Twitter API, you first have to register as a Twitter developer on the developersâ€™ website. https://developer.twitter.com/en\n",
    "2. Once registered, you need to create a Twitter application thatâ€™ll set up a bunch of credentials. These credentials will be later used by the Tweepy library in order to authenticate you.\n",
    "* 1) Go to the developerâ€™s dashboard.\n",
    "* 2) Hit Overview from the left sidebar and click on the Create App button.\n",
    "* 3) Give your app a name.\n",
    "* 4) This will generate the following credentials. Theyâ€™re personal: donâ€™t share them with anybody.\n",
    "\n",
    " * #### API_KEY\n",
    " * #### API_KEY_SECRET\n",
    " * #### ACCESS_TOKEN\n",
    " * #### ACCESS_TOKEN_SECRET\n",
    " * #### BEARER_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0298af5",
   "metadata": {},
   "source": [
    "## 2. Install Tweepy and call it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea2faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweepy is a free Python wrapper that makes it easier to authenticate and interact with the Twitter API.\n",
    "# install tweepy \n",
    "#! pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa2391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python modules to work with Twitter data\n",
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0e73a",
   "metadata": {},
   "source": [
    "## 3. Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c8298",
   "metadata": {},
   "source": [
    "#### To access Twitter data, you will need to authenticate your account using your API keys and tokens. \n",
    "#### We added our credentials to a txt file in advance. We will read the keys from the txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bcb23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read twitter authorication keys from txt file\n",
    "keys = []\n",
    "with open('Twitter_Keys.txt') as f:\n",
    "    for line in f:\n",
    "        keys.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79bb3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=keys[0] # consumer_key = 'YourConsumerKey'\n",
    "consumer_secret=keys[1] # consumer_secret = 'YourConsumerSecret'\n",
    "access_token=keys[2] # access_token = 'YourAccessToken'\n",
    "access_token_secret=keys[3] # access_token_secret = 'YourAccessTokenSecret'\n",
    "bearer_token = keys[4] # bearer_token = 'YourBearerToken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7320d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API v2 Client\n",
    "# put your credentials in tweepy.Client to authenticate your account\n",
    "client = tweepy.Client(consumer_key=consumer_key,\n",
    "                       consumer_secret=consumer_secret,\n",
    "                       access_token=access_token,\n",
    "                       access_token_secret = access_token_secret,\n",
    "                       bearer_token=bearer_token,\n",
    "                       wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bb2e4",
   "metadata": {},
   "source": [
    "## 4. Search tweets by hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84e1d9",
   "metadata": {},
   "source": [
    "* Here we are going to searching tweets by `#uoft`. \n",
    "* We can do this by building a search query and using the function search_recent_tweets(). \n",
    "* But it only returns the tweet id and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8899e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(data=[<Tweet id=1592389643613638656 text='#UofT Completed: The scheduled maintenance has been completed. https://t.co/99BqV2Rd6Q'>, <Tweet id=1592381946256330752 text='#UofT In Progress: Scheduled maintenance is currently in progress. We will provide updates as necessary. https://t.co/8pkaK6M18Z'>, <Tweet id=1592375948196073472 text=\"RT @UofTfamilycare: It's #transawarenessweek. Check out the FCO's blog for events across #uoft as well as resources.\\nhttps://t.co/BnjKiVYpBâ€¦\">, <Tweet id=1592375575896764417 text=\"RT @UofTFNH: It's #RockYourMocs week, November 13-19th 2022!\\nCome visit the Resource Centre at First Nations House Indigenous Student Serviâ€¦\">, <Tweet id=1592375539683115009 text='RT @cupe3261: Since 2020, #UofT contracted out cleaning in an additional 27 buildings at the St. George campus, cutting good jobs and creatâ€¦'>, <Tweet id=1592374830375976960 text=\"RT @uoftbrn: BRN Speaker Series: Join @UTSC's Caroline Hossein and Ebun Joseph (@EbunJoseph1), a lecturer @ucddublin, for a conversation abâ€¦\">, <Tweet id=1592372062227955715 text=\"RT @UofTFNH: It's #RockYourMocs week, November 13-19th 2022!\\nCome visit the Resource Centre at First Nations House Indigenous Student Serviâ€¦\">, <Tweet id=1592371236038119424 text='Hey #UofT community, there is still time to register for our event this Wednesday (November 16, 4-5:30pm)!\\n\\nClick the link below to register!\\nhttps://t.co/MwbJ5WpsRO https://t.co/d3fNrcakDm'>, <Tweet id=1592366914512519169 text='#UofT Scheduled (Nov 15, 2022, 00:00 EST): Maintenance will begin as scheduled in 60 minutes. https://t.co/fAMCBGNQJ9'>, <Tweet id=1592364984272494592 text=\"RT @uoftbrn: BRN Speaker Series: Join @UTSC's Caroline Hossein and Ebun Joseph (@EbunJoseph1), a lecturer @ucddublin, for a conversation abâ€¦\">], includes={}, errors=[], meta={'newest_id': '1592389643613638656', 'oldest_id': '1592364984272494592', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fpzhk2477tna42tl2hnrl62g1u8ozh'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweepy.client.Response"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_search = client.search_recent_tweets(query=\"#uoft\", max_results=10)\n",
    "print(uoft_search)\n",
    "type(uoft_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b4ccd",
   "metadata": {},
   "source": [
    "## 5. Converting Information to DataFrame and Exporting as CSV\n",
    "\n",
    "If we want to see more information about tweets, we can use `Expansions` to expand the information included in the metadata beyond the default. For this example, I want to also retrieve the author of the tweet (author_id).\n",
    "\n",
    "By default, the Tweet object only returns the id and the text fields. If you need the Tweetâ€™s created date or public metrics, you will need to use the `tweet.fields` parameters to request them. `public_metrics` includes retweets, replies, likes information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9d2ac",
   "metadata": {},
   "source": [
    "* Introduce `Expansions`: https://developer.twitter.com/en/docs/twitter-api/expansions\n",
    "* Introduce `Fields` : https://developer.twitter.com/en/docs/twitter-api/fields\n",
    "* More functions to get metadata: https://docs.tweepy.org/en/stable/expansions_and_fields.html#tweet-fields-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0991d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansions enable you to request additional data objects \n",
    "# that relate to the originally returned List, Space, Tweets, or users.\n",
    "uoft_search = client.search_recent_tweets(\n",
    "    query=\"#uoft -is:retweet lang:en\", # Extract non-retweeted English tweets\n",
    "    max_results=100, \n",
    "    expansions=[\"author_id\"],\n",
    "    tweet_fields= [\"created_at,public_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3013f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our data set\n",
    "data = []\n",
    "\n",
    "# set the columns\n",
    "columns = ['ID', 'Tweet', \"Date Posted\",'Author ID', 'Liked', 'Reply', 'Retweet']\n",
    "\n",
    "# create a dictionary that will use the author_id field to look up more information \n",
    "# about the users\n",
    "uoft_users = {user['id']: \n",
    "    user for user in uoft_search.includes['users']}\n",
    "\n",
    "# add the data from our retieval to the data set\n",
    "for tweet in uoft_search.data:\n",
    "    if uoft_users[tweet.author_id]:\n",
    "        user = uoft_users[tweet.author_id]\n",
    "        data.append([tweet.id, \n",
    "                     tweet.text, \n",
    "                     tweet.created_at, \n",
    "                     user.username,  \n",
    "                     tweet.public_metrics['like_count'], \n",
    "                     tweet.public_metrics['reply_count'],\n",
    "                     tweet.public_metrics['retweet_count']])\n",
    "    \n",
    "# create the dataframe\n",
    "uoft_df = pd.DataFrame(data, columns=columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "316b9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data as csv\n",
    "uoft_df.to_csv(\"uoft_tweets_current.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f354ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read we pre saved uoft_tweets_Nov13.csv to run the following steps\n",
    "uoft_df = pd.read_csv('uoft_tweets_Nov13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc1718b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1591977857664024576</td>\n",
       "      <td>Dont forget to donate to CIUT FM !!! The only ...</td>\n",
       "      <td>2022-11-14 02:14:33+00:00</td>\n",
       "      <td>smhimh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1591938939669352448</td>\n",
       "      <td>Happy first day of snow to everyone in Toronto...</td>\n",
       "      <td>2022-11-13 23:39:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1591937427085598721</td>\n",
       "      <td>How are we feeling on the last day of reading ...</td>\n",
       "      <td>2022-11-13 23:33:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1591936122674085890</td>\n",
       "      <td>#SelfCareSunday Since eating is an important p...</td>\n",
       "      <td>2022-11-13 23:28:43+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1591925903936061440</td>\n",
       "      <td>Faculty of Fall\\n\\n15 sec mp4 720â€ŠÃ—â€Š1280 11.8 ...</td>\n",
       "      <td>2022-11-13 22:48:06+00:00</td>\n",
       "      <td>michaelalstad</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>1590883872027598850</td>\n",
       "      <td>Recently published: A mathematical framework t...</td>\n",
       "      <td>2022-11-11 01:47:26+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1590883568099762176</td>\n",
       "      <td>Recently published: A mathematical framework t...</td>\n",
       "      <td>2022-11-11 01:46:14+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1590875152988114945</td>\n",
       "      <td>Life can be challenging but there are resource...</td>\n",
       "      <td>2022-11-11 01:12:48+00:00</td>\n",
       "      <td>UTSC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1590862298620436480</td>\n",
       "      <td>Watch LIVE on YouTube: Contemporary Indigenous...</td>\n",
       "      <td>2022-11-11 00:21:43+00:00</td>\n",
       "      <td>UofTDaniels</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1590833628271226880</td>\n",
       "      <td>Wake up #Canada #Vancouver #LongCovid #UBC #Uo...</td>\n",
       "      <td>2022-11-10 22:27:47+00:00</td>\n",
       "      <td>PeterTell3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                   ID  \\\n",
       "0            0  1591977857664024576   \n",
       "1            1  1591938939669352448   \n",
       "2            2  1591937427085598721   \n",
       "3            3  1591936122674085890   \n",
       "4            4  1591925903936061440   \n",
       "..         ...                  ...   \n",
       "95          95  1590883872027598850   \n",
       "96          96  1590883568099762176   \n",
       "97          97  1590875152988114945   \n",
       "98          98  1590862298620436480   \n",
       "99          99  1590833628271226880   \n",
       "\n",
       "                                                Tweet  \\\n",
       "0   Dont forget to donate to CIUT FM !!! The only ...   \n",
       "1   Happy first day of snow to everyone in Toronto...   \n",
       "2   How are we feeling on the last day of reading ...   \n",
       "3   #SelfCareSunday Since eating is an important p...   \n",
       "4   Faculty of Fall\\n\\n15 sec mp4 720â€ŠÃ—â€Š1280 11.8 ...   \n",
       "..                                                ...   \n",
       "95  Recently published: A mathematical framework t...   \n",
       "96  Recently published: A mathematical framework t...   \n",
       "97  Life can be challenging but there are resource...   \n",
       "98  Watch LIVE on YouTube: Contemporary Indigenous...   \n",
       "99  Wake up #Canada #Vancouver #LongCovid #UBC #Uo...   \n",
       "\n",
       "                  Date Posted      Author ID  Liked  Reply  Retweet  \n",
       "0   2022-11-14 02:14:33+00:00         smhimh      0      0        0  \n",
       "1   2022-11-13 23:39:54+00:00        uoftmha      1      0        0  \n",
       "2   2022-11-13 23:33:54+00:00        uoftmha      0      0        0  \n",
       "3   2022-11-13 23:28:43+00:00        uoftmha      0      0        0  \n",
       "4   2022-11-13 22:48:06+00:00  michaelalstad      5      0        0  \n",
       "..                        ...            ...    ...    ...      ...  \n",
       "95  2022-11-11 01:47:26+00:00      sourojeet      0      0        0  \n",
       "96  2022-11-11 01:46:14+00:00      sourojeet      0      0        0  \n",
       "97  2022-11-11 01:12:48+00:00           UTSC      2      0        1  \n",
       "98  2022-11-11 00:21:43+00:00    UofTDaniels      1      0        0  \n",
       "99  2022-11-10 22:27:47+00:00     PeterTell3      1      0        0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24d8e8",
   "metadata": {},
   "source": [
    "# Part 2: Basic Feature Extraction & Basic Text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b7ffe",
   "metadata": {},
   "source": [
    "## 1. Basic feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa37ef",
   "metadata": {},
   "source": [
    "#### Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83774039",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df[\"Number_of_words\"] = uoft_df[\"Tweet\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc433620",
   "metadata": {},
   "source": [
    "#### Number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f683a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df[\"Number_of_characters\"] = uoft_df[\"Tweet\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1aac97",
   "metadata": {},
   "source": [
    "#### Average word length for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e855543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_word_length = []\n",
    "for i in uoft_df['Tweet']:\n",
    "    words = i.split()\n",
    "    average = sum(len(word) for word in words) / len(words)\n",
    "    average_word_length.append(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b90d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df[\"Average_word_length\"] = average_word_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138761a",
   "metadata": {},
   "source": [
    "#### Number of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d2e4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the nltk package to count the stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f7608a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df['Number_of_stopwords'] = uoft_df['Tweet'].apply(lambda x: len([w for w in x.split() if w in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e68011",
   "metadata": {},
   "source": [
    "### Now we could know the basic information of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70da88a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Number_of_words</th>\n",
       "      <th>Number_of_characters</th>\n",
       "      <th>Average_word_length</th>\n",
       "      <th>Number_of_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1591977857664024576</td>\n",
       "      <td>Dont forget to donate to CIUT FM !!! The only ...</td>\n",
       "      <td>2022-11-14 02:14:33+00:00</td>\n",
       "      <td>smhimh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>257</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1591938939669352448</td>\n",
       "      <td>Happy first day of snow to everyone in Toronto...</td>\n",
       "      <td>2022-11-13 23:39:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>180</td>\n",
       "      <td>8.368421</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1591937427085598721</td>\n",
       "      <td>How are we feeling on the last day of reading ...</td>\n",
       "      <td>2022-11-13 23:33:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>277</td>\n",
       "      <td>5.756098</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1591936122674085890</td>\n",
       "      <td>#SelfCareSunday Since eating is an important p...</td>\n",
       "      <td>2022-11-13 23:28:43+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>255</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1591925903936061440</td>\n",
       "      <td>Faculty of Fall\\n\\n15 sec mp4 720â€ŠÃ—â€Š1280 11.8 ...</td>\n",
       "      <td>2022-11-13 22:48:06+00:00</td>\n",
       "      <td>michaelalstad</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>202</td>\n",
       "      <td>6.769231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>1590883872027598850</td>\n",
       "      <td>Recently published: A mathematical framework t...</td>\n",
       "      <td>2022-11-11 01:47:26+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>237</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1590883568099762176</td>\n",
       "      <td>Recently published: A mathematical framework t...</td>\n",
       "      <td>2022-11-11 01:46:14+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>241</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1590875152988114945</td>\n",
       "      <td>Life can be challenging but there are resource...</td>\n",
       "      <td>2022-11-11 01:12:48+00:00</td>\n",
       "      <td>UTSC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>264</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1590862298620436480</td>\n",
       "      <td>Watch LIVE on YouTube: Contemporary Indigenous...</td>\n",
       "      <td>2022-11-11 00:21:43+00:00</td>\n",
       "      <td>UofTDaniels</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>212</td>\n",
       "      <td>7.791667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1590833628271226880</td>\n",
       "      <td>Wake up #Canada #Vancouver #LongCovid #UBC #Uo...</td>\n",
       "      <td>2022-11-10 22:27:47+00:00</td>\n",
       "      <td>PeterTell3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                   ID  \\\n",
       "0            0  1591977857664024576   \n",
       "1            1  1591938939669352448   \n",
       "2            2  1591937427085598721   \n",
       "3            3  1591936122674085890   \n",
       "4            4  1591925903936061440   \n",
       "..         ...                  ...   \n",
       "95          95  1590883872027598850   \n",
       "96          96  1590883568099762176   \n",
       "97          97  1590875152988114945   \n",
       "98          98  1590862298620436480   \n",
       "99          99  1590833628271226880   \n",
       "\n",
       "                                                Tweet  \\\n",
       "0   Dont forget to donate to CIUT FM !!! The only ...   \n",
       "1   Happy first day of snow to everyone in Toronto...   \n",
       "2   How are we feeling on the last day of reading ...   \n",
       "3   #SelfCareSunday Since eating is an important p...   \n",
       "4   Faculty of Fall\\n\\n15 sec mp4 720â€ŠÃ—â€Š1280 11.8 ...   \n",
       "..                                                ...   \n",
       "95  Recently published: A mathematical framework t...   \n",
       "96  Recently published: A mathematical framework t...   \n",
       "97  Life can be challenging but there are resource...   \n",
       "98  Watch LIVE on YouTube: Contemporary Indigenous...   \n",
       "99  Wake up #Canada #Vancouver #LongCovid #UBC #Uo...   \n",
       "\n",
       "                  Date Posted      Author ID  Liked  Reply  Retweet  \\\n",
       "0   2022-11-14 02:14:33+00:00         smhimh      0      0        0   \n",
       "1   2022-11-13 23:39:54+00:00        uoftmha      1      0        0   \n",
       "2   2022-11-13 23:33:54+00:00        uoftmha      0      0        0   \n",
       "3   2022-11-13 23:28:43+00:00        uoftmha      0      0        0   \n",
       "4   2022-11-13 22:48:06+00:00  michaelalstad      5      0        0   \n",
       "..                        ...            ...    ...    ...      ...   \n",
       "95  2022-11-11 01:47:26+00:00      sourojeet      0      0        0   \n",
       "96  2022-11-11 01:46:14+00:00      sourojeet      0      0        0   \n",
       "97  2022-11-11 01:12:48+00:00           UTSC      2      0        1   \n",
       "98  2022-11-11 00:21:43+00:00    UofTDaniels      1      0        0   \n",
       "99  2022-11-10 22:27:47+00:00     PeterTell3      1      0        0   \n",
       "\n",
       "    Number_of_words  Number_of_characters  Average_word_length  \\\n",
       "0                36                   257             6.166667   \n",
       "1                19                   180             8.368421   \n",
       "2                41                   277             5.756098   \n",
       "3                34                   255             6.470588   \n",
       "4                26                   202             6.769231   \n",
       "..              ...                   ...                  ...   \n",
       "95               24                   237             8.833333   \n",
       "96               24                   241             9.000000   \n",
       "97               33                   264             6.909091   \n",
       "98               24                   212             7.791667   \n",
       "99               15                   129             7.666667   \n",
       "\n",
       "    Number_of_stopwords  \n",
       "0                    10  \n",
       "1                     3  \n",
       "2                    11  \n",
       "3                     7  \n",
       "4                     1  \n",
       "..                  ...  \n",
       "95                    4  \n",
       "96                    4  \n",
       "97                    8  \n",
       "98                    4  \n",
       "99                    1  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db0049",
   "metadata": {},
   "source": [
    "### But by observing the below text data, there is too much â€˜noiseâ€™. \n",
    "### Therefore, we need to clean the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ef3741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dont forget to donate to CIUT FM !!! The only radio station i know that doesnâ€™t have commercials and constantly has spellbinding shows and programs throughout the week #collegeradio #toronto #canada #UofT #modern #listenersupported #spokenword #NewMusic2022'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca829de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happy first day of snow to everyone in Toronto!!â„ï¸â˜ƒï¸ðŸ¤\\n\\n#TorontoWeather #snowfall #Weather #WINTER #uoft #relax #SnowFlake #MentalHealthAwareness #positive \\n\\nhttps://t.co/onJLVz44oK'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25725740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are we feeling on the last day of reading weekðŸ˜­ Time flew by and I was extremely unproductive study-wise, but hey atleast I got a relaxing week to myself! â¤ï¸ \\n#uoft #toronto #readingweek #student #studentlife #mentalhealth #studyspo #relax #positive https://t.co/UVJ6nuOeEC'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c71e1",
   "metadata": {},
   "source": [
    "## 2. Basic text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8089a3",
   "metadata": {},
   "source": [
    "#### Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d062e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df[\"Tweet\"] = uoft_df[\"Tweet\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9371f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are we feeling on the last day of reading weekðŸ˜­ time flew by and i was extremely unproductive study-wise, but hey atleast i got a relaxing week to myself! â¤ï¸ \\n#uoft #toronto #readingweek #student #studentlife #mentalhealth #studyspo #relax #positive https://t.co/uvj6nuoeec'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3ff6",
   "metadata": {},
   "source": [
    "#### Remove all emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2bd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii') #it encodes a unicode string to ascii and ignores errors\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea170c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df[\"Tweet\"] = uoft_df[\"Tweet\"].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26898d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are we feeling on the last day of reading week time flew by and i was extremely unproductive study-wise, but hey atleast i got a relaxing week to myself!  \\n#uoft #toronto #readingweek #student #studentlife #mentalhealth #studyspo #relax #positive https://t.co/uvj6nuoeec'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df[\"Tweet\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89fec90",
   "metadata": {},
   "source": [
    "#### Remove  all URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaddad33",
   "metadata": {},
   "source": [
    "* #### import `re` to replace a pattern in string by the a certain replacement. Details refer to https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f9b002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e18ca163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the 're.sub' to remove urls.\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"www.(\\w+)\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ada4d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to remove all urls\n",
    "uoft_df[\"Tweet\"] = uoft_df[\"Tweet\"].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eaab110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are we feeling on the last day of reading week time flew by and i was extremely unproductive study-wise, but hey atleast i got a relaxing week to myself!  \\n#uoft #toronto #readingweek #student #studentlife #mentalhealth #studyspo #relax #positive '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3381ce",
   "metadata": {},
   "source": [
    "#### Remove all punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3c9e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "845218ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the 're.sub' to remove punctuation.\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e05b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to remove all punctuation\n",
    "uoft_df[\"Tweet\"] = uoft_df[\"Tweet\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "292739e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how are we feeling on the last day of reading week time flew by and i was extremely unproductive studywise but hey atleast i got a relaxing week to myself  \\nuoft toronto readingweek student studentlife mentalhealth studyspo relax positive '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73567d0f",
   "metadata": {},
   "source": [
    "#### Remove stopwords\n",
    "You can see that stopwords are these meaningless pronouns or prepositions. Removing these meaningless words will help us focus on keywords in the further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b60d5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk package to find stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db825a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df['Tweet'] = uoft_df['Tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09e856d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feeling last day reading week time flew extremely unproductive studywise hey atleast got relaxing week uoft toronto readingweek student studentlife mentalhealth studyspo relax positive'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ba23f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5412e90",
   "metadata": {},
   "source": [
    "#### Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2c8b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/ruiyang/opt/anaconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/ruiyang/opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in /Users/ruiyang/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/ruiyang/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ruiyang/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /Users/ruiyang/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.62.3)\n"
     ]
    }
   ],
   "source": [
    "# using Textbolb libiary to do the spelling correction\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31b4125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df['Tweet'] = uoft_df.Tweet.apply(lambda txt: ''.join(TextBlob(txt).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e9c1183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feeling last day reading week time flew extremely productive studywise hey least got relaxing week soft toronto readingweek student studentlife mentalhealth studyspo relax positive'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['Tweet'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d0906",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "Tokenizers can divide strings into lists of substrings. Then we can try to understand the meaning of the text by analyzing the smaller units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6cfa160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9278e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df['tokenized'] = uoft_df.Tweet.apply(lambda txt:nltk.word_tokenize(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22c2e10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feeling',\n",
       " 'last',\n",
       " 'day',\n",
       " 'reading',\n",
       " 'week',\n",
       " 'time',\n",
       " 'flew',\n",
       " 'extremely',\n",
       " 'productive',\n",
       " 'studywise',\n",
       " 'hey',\n",
       " 'least',\n",
       " 'got',\n",
       " 'relaxing',\n",
       " 'week',\n",
       " 'soft',\n",
       " 'toronto',\n",
       " 'readingweek',\n",
       " 'student',\n",
       " 'studentlife',\n",
       " 'mentalhealth',\n",
       " 'studyspo',\n",
       " 'relax',\n",
       " 'positive']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['tokenized'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af3030",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "Stemming is a process that stems or removes the last few characters from a word, sometimes leading to incorrect meanings and spelling.\n",
    "* For instance, stemming the word 'Caring' would return 'Car'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73a5454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PorterStemmer to do stemming\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cc4ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem each words from the tokenized tweet and then join the stem words together\n",
    "porter = PorterStemmer()\n",
    "final = []\n",
    "for i in uoft_df['tokenized']:\n",
    "        stem_sentence=[]\n",
    "        for word in i:\n",
    "            stem_sentence.append(porter.stem(word))\n",
    "            stem_sentence.append(\" \")\n",
    "        final.append(\"\".join(stem_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d323bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df['stem'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e3b7d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feel last day read week time flew extrem product studywis hey least got relax week soft toronto readingweek student studentlif mentalhealth studyspo relax posit '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['stem'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4276354",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "Lemmatization considers the context and converts the word to its meaningful base form.\n",
    "* For example, lemmatizing the word â€˜Caringâ€˜ would return â€˜Careâ€˜."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c542e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fc3f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9916739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize each words from the tokenized tweets and then join the lemmatized words together\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "final_lem = []\n",
    "for i in uoft_df['tokenized']:\n",
    "        lem_sentence=[]\n",
    "        for word in i:\n",
    "            lem_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
    "            lem_sentence.append(\" \")\n",
    "        final_lem.append(\"\".join(lem_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bc18175",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df['lemmatization'] = final_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24cc4704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feeling last day reading week time flew extremely productive studywise hey least got relaxing week soft toronto readingweek student studentlife mentalhealth studyspo relax positive '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df['lemmatization'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6018e901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Number_of_words</th>\n",
       "      <th>Number_of_characters</th>\n",
       "      <th>Average_word_length</th>\n",
       "      <th>Number_of_stopwords</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stem</th>\n",
       "      <th>lemmatization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1591977857664024576</td>\n",
       "      <td>dont forget donate cut am radio station know d...</td>\n",
       "      <td>2022-11-14 02:14:33+00:00</td>\n",
       "      <td>smhimh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>257</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>10</td>\n",
       "      <td>[dont, forget, donate, cut, am, radio, station...</td>\n",
       "      <td>dont forget donat cut am radio station know do...</td>\n",
       "      <td>dont forget donate cut am radio station know d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1591938939669352448</td>\n",
       "      <td>happy first day snow everyone toronto torontow...</td>\n",
       "      <td>2022-11-13 23:39:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>180</td>\n",
       "      <td>8.368421</td>\n",
       "      <td>3</td>\n",
       "      <td>[happy, first, day, snow, everyone, toronto, t...</td>\n",
       "      <td>happi first day snow everyon toronto torontowe...</td>\n",
       "      <td>happy first day snow everyone toronto torontow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1591937427085598721</td>\n",
       "      <td>feeling last day reading week time flew extrem...</td>\n",
       "      <td>2022-11-13 23:33:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>277</td>\n",
       "      <td>5.756098</td>\n",
       "      <td>11</td>\n",
       "      <td>[feeling, last, day, reading, week, time, flew...</td>\n",
       "      <td>feel last day read week time flew extrem produ...</td>\n",
       "      <td>feeling last day reading week time flew extrem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1591936122674085890</td>\n",
       "      <td>selfcaresunday since eating important part sel...</td>\n",
       "      <td>2022-11-13 23:28:43+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>255</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>7</td>\n",
       "      <td>[selfcaresunday, since, eating, important, par...</td>\n",
       "      <td>selfcaresunday sinc eat import part self care ...</td>\n",
       "      <td>selfcaresunday since eating important part sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1591925903936061440</td>\n",
       "      <td>faculty fall 15 see may 7201280 118 mb 99100 t...</td>\n",
       "      <td>2022-11-13 22:48:06+00:00</td>\n",
       "      <td>michaelalstad</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>202</td>\n",
       "      <td>6.769231</td>\n",
       "      <td>1</td>\n",
       "      <td>[faculty, fall, 15, see, may, 7201280, 118, mb...</td>\n",
       "      <td>faculti fall 15 see may 7201280 118 mb 99100 t...</td>\n",
       "      <td>faculty fall 15 see may 7201280 118 mb 99100 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>1590883872027598850</td>\n",
       "      <td>recently published mathematical framework unde...</td>\n",
       "      <td>2022-11-11 01:47:26+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>237</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>4</td>\n",
       "      <td>[recently, published, mathematical, framework,...</td>\n",
       "      <td>recent publish mathemat framework understand p...</td>\n",
       "      <td>recently published mathematical framework unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1590883568099762176</td>\n",
       "      <td>recently published mathematical framework unde...</td>\n",
       "      <td>2022-11-11 01:46:14+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>241</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>[recently, published, mathematical, framework,...</td>\n",
       "      <td>recent publish mathemat framework understand p...</td>\n",
       "      <td>recently published mathematical framework unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1590875152988114945</td>\n",
       "      <td>life challenging resources available help see ...</td>\n",
       "      <td>2022-11-11 01:12:48+00:00</td>\n",
       "      <td>UTSC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>264</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>8</td>\n",
       "      <td>[life, challenging, resources, available, help...</td>\n",
       "      <td>life challeng resourc avail help see hard time...</td>\n",
       "      <td>life challenging resource available help see h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1590862298620436480</td>\n",
       "      <td>watch live couture contemporary indigenous per...</td>\n",
       "      <td>2022-11-11 00:21:43+00:00</td>\n",
       "      <td>UofTDaniels</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>212</td>\n",
       "      <td>7.791667</td>\n",
       "      <td>4</td>\n",
       "      <td>[watch, live, couture, contemporary, indigenou...</td>\n",
       "      <td>watch live coutur contemporari indigen perform...</td>\n",
       "      <td>watch live couture contemporary indigenous per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1590833628271226880</td>\n",
       "      <td>wake canada vancouver longcovid bc soft of col...</td>\n",
       "      <td>2022-11-10 22:27:47+00:00</td>\n",
       "      <td>PeterTell3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>[wake, canada, vancouver, longcovid, bc, soft,...</td>\n",
       "      <td>wake canada vancouv longcovid bc soft of coli ...</td>\n",
       "      <td>wake canada vancouver longcovid bc soft of col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                   ID  \\\n",
       "0            0  1591977857664024576   \n",
       "1            1  1591938939669352448   \n",
       "2            2  1591937427085598721   \n",
       "3            3  1591936122674085890   \n",
       "4            4  1591925903936061440   \n",
       "..         ...                  ...   \n",
       "95          95  1590883872027598850   \n",
       "96          96  1590883568099762176   \n",
       "97          97  1590875152988114945   \n",
       "98          98  1590862298620436480   \n",
       "99          99  1590833628271226880   \n",
       "\n",
       "                                                Tweet  \\\n",
       "0   dont forget donate cut am radio station know d...   \n",
       "1   happy first day snow everyone toronto torontow...   \n",
       "2   feeling last day reading week time flew extrem...   \n",
       "3   selfcaresunday since eating important part sel...   \n",
       "4   faculty fall 15 see may 7201280 118 mb 99100 t...   \n",
       "..                                                ...   \n",
       "95  recently published mathematical framework unde...   \n",
       "96  recently published mathematical framework unde...   \n",
       "97  life challenging resources available help see ...   \n",
       "98  watch live couture contemporary indigenous per...   \n",
       "99  wake canada vancouver longcovid bc soft of col...   \n",
       "\n",
       "                  Date Posted      Author ID  Liked  Reply  Retweet  \\\n",
       "0   2022-11-14 02:14:33+00:00         smhimh      0      0        0   \n",
       "1   2022-11-13 23:39:54+00:00        uoftmha      1      0        0   \n",
       "2   2022-11-13 23:33:54+00:00        uoftmha      0      0        0   \n",
       "3   2022-11-13 23:28:43+00:00        uoftmha      0      0        0   \n",
       "4   2022-11-13 22:48:06+00:00  michaelalstad      5      0        0   \n",
       "..                        ...            ...    ...    ...      ...   \n",
       "95  2022-11-11 01:47:26+00:00      sourojeet      0      0        0   \n",
       "96  2022-11-11 01:46:14+00:00      sourojeet      0      0        0   \n",
       "97  2022-11-11 01:12:48+00:00           UTSC      2      0        1   \n",
       "98  2022-11-11 00:21:43+00:00    UofTDaniels      1      0        0   \n",
       "99  2022-11-10 22:27:47+00:00     PeterTell3      1      0        0   \n",
       "\n",
       "    Number_of_words  Number_of_characters  Average_word_length  \\\n",
       "0                36                   257             6.166667   \n",
       "1                19                   180             8.368421   \n",
       "2                41                   277             5.756098   \n",
       "3                34                   255             6.470588   \n",
       "4                26                   202             6.769231   \n",
       "..              ...                   ...                  ...   \n",
       "95               24                   237             8.833333   \n",
       "96               24                   241             9.000000   \n",
       "97               33                   264             6.909091   \n",
       "98               24                   212             7.791667   \n",
       "99               15                   129             7.666667   \n",
       "\n",
       "    Number_of_stopwords                                          tokenized  \\\n",
       "0                    10  [dont, forget, donate, cut, am, radio, station...   \n",
       "1                     3  [happy, first, day, snow, everyone, toronto, t...   \n",
       "2                    11  [feeling, last, day, reading, week, time, flew...   \n",
       "3                     7  [selfcaresunday, since, eating, important, par...   \n",
       "4                     1  [faculty, fall, 15, see, may, 7201280, 118, mb...   \n",
       "..                  ...                                                ...   \n",
       "95                    4  [recently, published, mathematical, framework,...   \n",
       "96                    4  [recently, published, mathematical, framework,...   \n",
       "97                    8  [life, challenging, resources, available, help...   \n",
       "98                    4  [watch, live, couture, contemporary, indigenou...   \n",
       "99                    1  [wake, canada, vancouver, longcovid, bc, soft,...   \n",
       "\n",
       "                                                 stem  \\\n",
       "0   dont forget donat cut am radio station know do...   \n",
       "1   happi first day snow everyon toronto torontowe...   \n",
       "2   feel last day read week time flew extrem produ...   \n",
       "3   selfcaresunday sinc eat import part self care ...   \n",
       "4   faculti fall 15 see may 7201280 118 mb 99100 t...   \n",
       "..                                                ...   \n",
       "95  recent publish mathemat framework understand p...   \n",
       "96  recent publish mathemat framework understand p...   \n",
       "97  life challeng resourc avail help see hard time...   \n",
       "98  watch live coutur contemporari indigen perform...   \n",
       "99  wake canada vancouv longcovid bc soft of coli ...   \n",
       "\n",
       "                                        lemmatization  \n",
       "0   dont forget donate cut am radio station know d...  \n",
       "1   happy first day snow everyone toronto torontow...  \n",
       "2   feeling last day reading week time flew extrem...  \n",
       "3   selfcaresunday since eating important part sel...  \n",
       "4   faculty fall 15 see may 7201280 118 mb 99100 t...  \n",
       "..                                                ...  \n",
       "95  recently published mathematical framework unde...  \n",
       "96  recently published mathematical framework unde...  \n",
       "97  life challenging resource available help see h...  \n",
       "98  watch live couture contemporary indigenous per...  \n",
       "99  wake canada vancouver longcovid bc soft of col...  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a89b61",
   "metadata": {},
   "source": [
    "## 3. Advanced text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf07551",
   "metadata": {},
   "source": [
    "#### Term Frequency (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ff6f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function to do term frequency \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85bc5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using countvectorizer from sklearn to achieve term frequency count\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c7f2576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0105', '100', '1020', '102176720495471221938', '105', '11', '118',\n",
       "       '12', '1200', '1200pm', '12130pm', '13', '14', '1418', '15',\n",
       "       '1517', '16', '17', '18', '18669255454', '18yearold', '2020',\n",
       "       '2022', '2304pm', '2330pm', '26', '27', '30', '305', '3711312',\n",
       "       '3800', '400pm', '4164952891', '4306pm', '50', '500pm', '7201280',\n",
       "       '99100', 'ac223', 'academic', 'academicpromotion',\n",
       "       'academictwitter', 'accepting', 'access', 'accommodation',\n",
       "       'account', 'across', 'activity', 'actually', 'adam', 'additional',\n",
       "       'address', 'adult', 'advice', 'advising', 'affect', 'agog', 'ai',\n",
       "       'alms', 'alongside', 'also', 'alum', 'alumni_utm', 'always', 'am',\n",
       "       'america', 'amp', 'anatomy', 'anchordown', 'ancient', 'and',\n",
       "       'anna', 'annette', 'annettemkennedy', 'announcement', 'answer',\n",
       "       'antitoxin', 'apologize', 'application', 'apply', 'applying',\n",
       "       'appointed', 'appreciate', 'approval', 'arc', 'architect',\n",
       "       'architecture', 'argue', 'armed', 'around', 'article', 'artist',\n",
       "       'artistic', 'ask', 'assessment', 'assignment', 'assured',\n",
       "       'astronomy', 'astronomyontap', 'astronomyontapto', 'asynchronous',\n",
       "       'athletic', 'attend', 'attended', 'author', 'available',\n",
       "       'awareness', 'back', 'bad', 'baize', 'banking', 'bar',\n",
       "       'basketball', 'batescollege', 'battled', 'bc', 'beautiful',\n",
       "       'become', 'bedardrubin', 'bell', 'benefit', 'best', 'big', 'board',\n",
       "       'bonstewart', 'booth', 'bowel', 'boxer', 'brand', 'brandy',\n",
       "       'break', 'breakfast', 'breath', 'brunn', 'bud', 'buffalo',\n",
       "       'building', 'busy', 'calling', 'calumny', 'camp', 'campusday',\n",
       "       'can', 'canada', 'canadian', 'captured', 'care', 'career',\n",
       "       'carried', 'category', 'cause', 'cdnchange', 'cdnpoli',\n",
       "       'celebrate', 'celebrating', 'celebration', 'centre', 'ceremony',\n",
       "       'chair', 'challenge', 'challenging', 'change', 'changed', 'chat',\n",
       "       'chatting', 'check', 'chemistry', 'choose', 'city', 'classof2022',\n",
       "       'cleanest', 'cleaning', 'click', 'closed', 'closing', 'cloud',\n",
       "       'coffee', 'coli', 'collection', 'college', 'collegeradio', 'come',\n",
       "       'comic', 'coming', 'commercial', 'common', 'community', 'computer',\n",
       "       'conceived', 'condition', 'conducting', 'conflict',\n",
       "       'congratulation', 'connaught', 'connect', 'considered',\n",
       "       'constantly', 'contemporary', 'contracted', 'contrary',\n",
       "       'contributed', 'contribution', 'conviction', 'convincing', 'cook',\n",
       "       'cooplife', 'cornell', 'could', 'council', 'course', 'couture',\n",
       "       'covid19', 'covidisairborne', 'create', 'creating', 'credit',\n",
       "       'creek', 'cris_uoft', 'crisis', 'cut', 'cutting', 'cuttingedge',\n",
       "       'd_schneiderman', 'daily', 'darlywilson', 'darylwilson', 'data',\n",
       "       'datavisualization', 'david', 'davis', 'day', 'dayton', 'deadline',\n",
       "       'dean', 'december', 'dedicated', 'degree', 'department',\n",
       "       'deserved', 'desktop', 'destiny', 'detail', 'development',\n",
       "       'diabetes', 'diary', 'died', 'dinner', 'direct437', 'director',\n",
       "       'disability', 'discipline', 'discover', 'discus', 'discussion',\n",
       "       'disease', 'disruption', 'diversity', 'do', 'doctorwho',\n",
       "       'document', 'doe', 'doesn', 'domyhomework', 'donate', 'done',\n",
       "       'dont', 'door', 'dr', 'drama', 'due', 'duke', 'dyzenhaus',\n",
       "       'earlycareer', 'earthsciences', 'easy', 'eat', 'eating',\n",
       "       'education', 'educator', 'effort', 'emigrant', 'employer',\n",
       "       'encouraged', 'engineering', 'ensure', 'entrepreneurship',\n",
       "       'environmental', 'equitable', 'equity', 'essay', 'essaypay', 'est',\n",
       "       'evening', 'event', 'everyone', 'exam', 'executed', 'executive',\n",
       "       'executiveeducation', 'expected', 'experience', 'expert',\n",
       "       'explore', 'extremely', 'facial', 'faculty', 'fairness', 'fall',\n",
       "       'fallcampusday', 'fallclasses', 'fallen', 'fantastic', 'fast',\n",
       "       'fdd2022', 'fear', 'feel', 'feeling', 'fell', 'feu', 'field',\n",
       "       'fieldtrip', 'fieldwork', 'final', 'finance', 'find', 'first',\n",
       "       'fish', 'fist', 'fitness', 'flagpole', 'flew', 'flex', 'florida',\n",
       "       'food', 'forget', 'former', 'forward', 'four', 'framework', 'free',\n",
       "       'friday', 'friend', 'front', 'full', 'fun', 'fund', 'game',\n",
       "       'gascons', 'gate', 'gathered', 'gentle', 'geology', 'geometric',\n",
       "       'george', 'geoscienceeducation', 'geosciences', 'gerontology',\n",
       "       'get', 'getting', 'gillespie', 'give', 'glad', 'global_uoft',\n",
       "       'goalsetting', 'gofriars', 'going', 'good', 'good2talk', 'got',\n",
       "       'grab', 'gradschool', 'graduate', 'graduated', 'granulating',\n",
       "       'granulation', 'graph', 'great', 'green', 'growing', 'gun',\n",
       "       'gutta', 'hall', 'happy', 'hard', 'harpmaree', 'harthouseuoft',\n",
       "       'health', 'healthy', 'hear', 'heart', 'held', 'help', 'helping',\n",
       "       'here', 'heritage', 'hey', 'highland', 'highlight', 'honor',\n",
       "       'honour', 'honoured', 'hopelessness', 'hour', 'housing',\n",
       "       'housingcrisis', 'huge', 'idea', 'identified', 'immensely',\n",
       "       'impact', 'importance', 'important', 'improve', 'in',\n",
       "       'inaccessibility', 'inaugural', 'inclusion', 'inconvenience',\n",
       "       'indigenous', 'industry', 'influential', 'informal', 'information',\n",
       "       'infrastructure', 'initiative', 'innovation', 'inspired',\n",
       "       'instruction', 'interesting', 'international', 'internship',\n",
       "       'interruption', 'into', 'introduction', 'investigation',\n",
       "       'involved', 'issue', 'it', 'jacqueline', 'jane', 'janitorial',\n",
       "       'january', 'javascript', 'jenniejareth', 'job', 'jobsearch',\n",
       "       'johnvoss', 'join', 'josephwongut', 'june', 'justice', 'keenest',\n",
       "       'kind', 'kizhigoo', 'knew', 'know', 'kylefarwell', 'laboratory',\n",
       "       'language', 'lascar', 'last', 'latest', 'lavallee', 'lead',\n",
       "       'leadership', 'leadershipmatters', 'leading', 'learn', 'learning',\n",
       "       'lease', 'least', 'leaving', 'lecture', 'legal', 'lens',\n",
       "       'lestweforget', 'librarian', 'library', 'life', 'like',\n",
       "       'lindajuot', 'line', 'linguistic', 'list', 'listenersupported',\n",
       "       'lister', 'live', 'lived', 'longcovid', 'look', 'looking',\n",
       "       'lorraine', 'lost', 'lounge', 'loving', 'made', 'magazine',\n",
       "       'maintain', 'maintena', 'maintenance', 'make', 'many', 'march',\n",
       "       'mark', 'mary', 'mass', 'masseycollege', 'master', 'match',\n",
       "       'mathematical', 'matter', 'may', 'mb', 'meet', 'member', 'memory',\n",
       "       'mental', 'mentalhealth', 'mentalhealthawareness',\n",
       "       'mentalhealthmatters', 'merit', 'miamidolphins', 'midterm',\n",
       "       'migizii', 'millerd99', 'mimi', 'mind', 'minute', 'miss',\n",
       "       'mississauga', 'mobile', 'moderate', 'modern', 'monday', 'morning',\n",
       "       'moscow', 'motivation', 'move', 'much', 'music', 'naples',\n",
       "       'national', 'nature', 'navigable', 'ndesrosiers', 'need',\n",
       "       'network', 'new', 'newest', 'newmusic2022', 'news', 'next',\n",
       "       'night', 'nomination', 'nordisk', 'normal', 'note', 'noted',\n",
       "       'notified', 'nov', 'november', 'novo', 'novonordiskca', 'number',\n",
       "       'nurse', 'nursing', 'objktcom', 'odor', 'of', 'offer', 'offered',\n",
       "       'oisegrad22', 'older', 'olympos', 'one', 'online', 'onlineclass',\n",
       "       'onlineclasses', 'ontario', 'onto', 'open', 'operational',\n",
       "       'opportunity', 'original', 'orlando', 'orlandomagic', 'paced',\n",
       "       'pad', 'panel', 'paperpay', 'part', 'partner', 'past', 'path',\n",
       "       'patience', 'pay', 'peace', 'peer', 'penned', 'pennnursing',\n",
       "       'performance', 'person', 'personal', 'petition', 'phdlife',\n",
       "       'philosopher', 'phone', 'photo', 'photographer', 'place',\n",
       "       'planned', 'play', 'please', 'plot', 'pm', 'poetry',\n",
       "       'policymakers', 'population', 'positive', 'possible', 'posted',\n",
       "       'potential', 'povertywage', 'power', 'practisewhatyouteach',\n",
       "       'praised', 'precisely', 'prefer', 'premier', 'preparation',\n",
       "       'present', 'presentation', 'president', 'press', 'pressing',\n",
       "       'principal', 'private', 'process', 'production', 'productive',\n",
       "       'prof', 'profession', 'professional', 'professionaldevelopment',\n",
       "       'professor', 'program', 'programming', 'promotion', 'prose',\n",
       "       'protecting', 'proud', 'provide', 'public', 'published', 'pulse',\n",
       "       'qualityautomotive', 'quercus', 'question', 'quick', 'quire',\n",
       "       'quitting', 'radio', 'randysi', 'ravine', 'reading', 'readingweek',\n",
       "       'ready', 'really', 'received', 'recently', 'recipe', 'recognition',\n",
       "       'recollect', 'redskyperforms', 'reflect', 'register',\n",
       "       'registration', 'related', 'relax', 'relaxing', 'relay',\n",
       "       'relevant', 'remember', 'remembering', 'remembers', 'remembrance',\n",
       "       'remembranceday', 'reminder', 'report', 'required', 'research',\n",
       "       'researcher', 'researchuoft', 'resolved', 'resource', 'respect',\n",
       "       'response', 'restoration', 'revitalization', 'riannuzzigpc',\n",
       "       'ridden', 'right', 'river', 'robert', 'romantic', 'room', 'rooted',\n",
       "       'roundtable', 'rutgerspride', 'sabres_science', 'sacrificed',\n",
       "       'saddle', 'sale', 'sample', 'sandralaronde', 'sap', 'saratoga',\n",
       "       'saturday', 'saved', 'say', 'scala', 'scale', 'scarborough',\n",
       "       'scarbto', 'scatter', 'schedule', 'school', 'science',\n",
       "       'scottpiatkowski', 'season', 'second', 'security', 'see',\n",
       "       'seeking', 'self', 'selfcaresunday', 'seminole', 'series',\n",
       "       'served', 'service', 'session', 'shah', 'share', 'shared', 'sharp',\n",
       "       'sheilamcmillan', 'show', 'showcasing', 'shutdown', 'sign',\n",
       "       'signature', 'significant', 'since', 'situation', 'skill', 'skin',\n",
       "       'smallpox', 'smelter', 'snack', 'snow', 'snowball', 'snowflake',\n",
       "       'social', 'socialwork', 'soft', 'softness', 'soldier', 'solution',\n",
       "       'sound', 'space', 'spacecoast', 'spellbinding', 'spiritual',\n",
       "       'spleen', 'spokenword', 'st', 'staff', 'stand', 'started',\n",
       "       'station', 'status', 'stay', 'stepped', 'still', 'storage',\n",
       "       'story', 'strengthened', 'student', 'studentlife', 'study',\n",
       "       'studyspo', 'studywise', 'submit', 'sum', 'sunday', 'support',\n",
       "       'supporter', 'sustainability', 'sustainabilityminded', 'system',\n",
       "       'tableau', 'take', 'talk', 'taniguchi', 'tap', 'tax', 'ten',\n",
       "       'terrified', 'test', 'tetanus', 'teutonic', 'texas', 'tezosart',\n",
       "       'tezoscommunity', 'thank', 'thanks', 'theme', 'thing', 'think',\n",
       "       'thirdannual', 'thomascollege', 'thoughtfully', 'thousand',\n",
       "       'three', 'throughout', 'thursday', 'ticket', 'time', 'tm', 'today',\n",
       "       'topic', 'toronto', 'torontotesla', 'torontoweather', 'tower',\n",
       "       'track', 'trainer', 'trans', 'transfer', 'trench', 'tress',\n",
       "       'tribute', 'trinitycollege', 'tuesday', 'tuft', 'tune', 'tuned',\n",
       "       'turkey', 'undergoing', 'undergraduate', 'understanding', 'unit',\n",
       "       'university', 'universityofsydney', 'universityoftoronto',\n",
       "       'unmotivated', 'uoft_dlsph', 'uoft_ihpst', 'uoftalumni',\n",
       "       'uoftartsci', 'uoftengineering', 'uoftgrad22', 'uoftkpe',\n",
       "       'uoftmagazine', 'uoftmedicine', 'uoftnursing', 'uoftsgdo',\n",
       "       'uoftsurgery', 'updated', 'urban', 'urbanleader', 'us', 'use',\n",
       "       'user', 'using', 'utmlangstudies', 'utscartscicoop',\n",
       "       'utscresearch', 'va', 'vancouver', 'veteran', 'via',\n",
       "       'viccollege_uoft', 'village', 'virtual', 'visit', 'visiting',\n",
       "       'visualization', 'vote', 'wait', 'wake', 'walk', 'want', 'war',\n",
       "       'warfare', 'watch', 'water', 'watson', 'way', 'we', 'weakness',\n",
       "       'weather', 'wednesday', 'week', 'weekend', 'weinrib', 'welcome',\n",
       "       'welfare', 'well', 'welling', 'wellnessutsc', 'westchase',\n",
       "       'winter', 'woman', 'wonderful', 'worker', 'workforce', 'working',\n",
       "       'workshop', 'world', 'worry', 'would', 'wreath', 'writerkait',\n",
       "       'www', 'year', 'young'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_transform data\n",
    "X = vectorizer.fit_transform(uoft_df['lemmatization'])\n",
    "# extract all the words present in lemmatization column\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cbc8dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of words frequency for each tweets\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "707bb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframe\n",
    "feature_extraction1 = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c49b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "uoft_df=uoft_df.join(feature_extraction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89c365f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Number_of_words</th>\n",
       "      <th>Number_of_characters</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>workshop</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>would</th>\n",
       "      <th>wreath</th>\n",
       "      <th>writerkait</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1591977857664024576</td>\n",
       "      <td>dont forget donate cut am radio station know d...</td>\n",
       "      <td>2022-11-14 02:14:33+00:00</td>\n",
       "      <td>smhimh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>257</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1591938939669352448</td>\n",
       "      <td>happy first day snow everyone toronto torontow...</td>\n",
       "      <td>2022-11-13 23:39:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1591937427085598721</td>\n",
       "      <td>feeling last day reading week time flew extrem...</td>\n",
       "      <td>2022-11-13 23:33:54+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1591936122674085890</td>\n",
       "      <td>selfcaresunday since eating important part sel...</td>\n",
       "      <td>2022-11-13 23:28:43+00:00</td>\n",
       "      <td>uoftmha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1591925903936061440</td>\n",
       "      <td>faculty fall 15 see may 7201280 118 mb 99100 t...</td>\n",
       "      <td>2022-11-13 22:48:06+00:00</td>\n",
       "      <td>michaelalstad</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>1590883872027598850</td>\n",
       "      <td>recently published mathematical framework unde...</td>\n",
       "      <td>2022-11-11 01:47:26+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>237</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1590883568099762176</td>\n",
       "      <td>recently published mathematical framework unde...</td>\n",
       "      <td>2022-11-11 01:46:14+00:00</td>\n",
       "      <td>sourojeet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1590875152988114945</td>\n",
       "      <td>life challenging resources available help see ...</td>\n",
       "      <td>2022-11-11 01:12:48+00:00</td>\n",
       "      <td>UTSC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>264</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1590862298620436480</td>\n",
       "      <td>watch live couture contemporary indigenous per...</td>\n",
       "      <td>2022-11-11 00:21:43+00:00</td>\n",
       "      <td>UofTDaniels</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>212</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1590833628271226880</td>\n",
       "      <td>wake canada vancouver longcovid bc soft of col...</td>\n",
       "      <td>2022-11-10 22:27:47+00:00</td>\n",
       "      <td>PeterTell3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 942 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                   ID  \\\n",
       "0            0  1591977857664024576   \n",
       "1            1  1591938939669352448   \n",
       "2            2  1591937427085598721   \n",
       "3            3  1591936122674085890   \n",
       "4            4  1591925903936061440   \n",
       "..         ...                  ...   \n",
       "95          95  1590883872027598850   \n",
       "96          96  1590883568099762176   \n",
       "97          97  1590875152988114945   \n",
       "98          98  1590862298620436480   \n",
       "99          99  1590833628271226880   \n",
       "\n",
       "                                                Tweet  \\\n",
       "0   dont forget donate cut am radio station know d...   \n",
       "1   happy first day snow everyone toronto torontow...   \n",
       "2   feeling last day reading week time flew extrem...   \n",
       "3   selfcaresunday since eating important part sel...   \n",
       "4   faculty fall 15 see may 7201280 118 mb 99100 t...   \n",
       "..                                                ...   \n",
       "95  recently published mathematical framework unde...   \n",
       "96  recently published mathematical framework unde...   \n",
       "97  life challenging resources available help see ...   \n",
       "98  watch live couture contemporary indigenous per...   \n",
       "99  wake canada vancouver longcovid bc soft of col...   \n",
       "\n",
       "                  Date Posted      Author ID  Liked  Reply  Retweet  \\\n",
       "0   2022-11-14 02:14:33+00:00         smhimh      0      0        0   \n",
       "1   2022-11-13 23:39:54+00:00        uoftmha      1      0        0   \n",
       "2   2022-11-13 23:33:54+00:00        uoftmha      0      0        0   \n",
       "3   2022-11-13 23:28:43+00:00        uoftmha      0      0        0   \n",
       "4   2022-11-13 22:48:06+00:00  michaelalstad      5      0        0   \n",
       "..                        ...            ...    ...    ...      ...   \n",
       "95  2022-11-11 01:47:26+00:00      sourojeet      0      0        0   \n",
       "96  2022-11-11 01:46:14+00:00      sourojeet      0      0        0   \n",
       "97  2022-11-11 01:12:48+00:00           UTSC      2      0        1   \n",
       "98  2022-11-11 00:21:43+00:00    UofTDaniels      1      0        0   \n",
       "99  2022-11-10 22:27:47+00:00     PeterTell3      1      0        0   \n",
       "\n",
       "    Number_of_words  Number_of_characters  ...  working  workshop world worry  \\\n",
       "0                36                   257  ...        0         0     0     0   \n",
       "1                19                   180  ...        0         0     0     0   \n",
       "2                41                   277  ...        0         0     0     0   \n",
       "3                34                   255  ...        0         0     0     0   \n",
       "4                26                   202  ...        0         0     0     0   \n",
       "..              ...                   ...  ...      ...       ...   ...   ...   \n",
       "95               24                   237  ...        0         0     0     0   \n",
       "96               24                   241  ...        0         0     0     0   \n",
       "97               33                   264  ...        0         0     0     0   \n",
       "98               24                   212  ...        0         0     0     0   \n",
       "99               15                   129  ...        0         0     0     0   \n",
       "\n",
       "   would  wreath  writerkait  www  year  young  \n",
       "0      0       0           0    0     0      0  \n",
       "1      0       0           0    0     0      0  \n",
       "2      0       0           0    0     0      0  \n",
       "3      0       0           0    0     0      0  \n",
       "4      0       0           0    0     0      0  \n",
       "..   ...     ...         ...  ...   ...    ...  \n",
       "95     0       0           0    0     0      0  \n",
       "96     0       0           0    0     0      0  \n",
       "97     0       0           0    0     0      0  \n",
       "98     0       0           0    0     0      0  \n",
       "99     0       0           0    0     0      0  \n",
       "\n",
       "[100 rows x 942 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d324ec8",
   "metadata": {},
   "source": [
    "# Part 3: Alternative way to get Twitter data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a10495",
   "metadata": {},
   "source": [
    "This method is much easier than extracting data from Twitter API. It doesn't need to create an account and generate the keys and tokens. Simply use the codes below, you can quickly scrape a bunch of information from Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11f635b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install alternative method to get Twitter data in Python  \n",
    "# pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24c517a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "#https://stackoverflow.com/questions/73485659/scrape-tweets-from-a-list-of-hashtags-using-snscrape\n",
    "def tweet_scraper(query, n_tweet):\n",
    "    attributes_container = []\n",
    "    max_tweet = n_tweet\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "        if i>max_tweet:\n",
    "            break\n",
    "        attributes_container.append([tweet.user.username,\n",
    "                                 tweet.user.created,\n",
    "                                 tweet.user.followersCount,\n",
    "                                 tweet.user.friendsCount,\n",
    "                                 tweet.retweetCount,\n",
    "                                 tweet.lang,\n",
    "                                 tweet.date,\n",
    "                                 tweet.likeCount,\n",
    "                                 tweet.sourceLabel,\n",
    "                                 tweet.id,\n",
    "                                 tweet.content,\n",
    "                                 tweet.hashtags,\n",
    "                                 tweet.conversationId,\n",
    "                                 tweet.inReplyToUser,\n",
    "                                 tweet.coordinates,\n",
    "                                 tweet.place])\n",
    "    \n",
    "    return pd.DataFrame(attributes_container, columns=[\"User\",\n",
    "                                                   \"Date_Created\",\n",
    "                                                   \"Follows_Count\",\n",
    "                                                   \"Friends_Count\",\n",
    "                                                   \"Retweet_Count\",\n",
    "                                                   \"Language\",\n",
    "                                                   \"Date_Tweet\",\n",
    "                                                   \"Number_of_Likes\",\n",
    "                                                   \"Source_of_Tweet\",\n",
    "                                                   \"Tweet_Id\",\n",
    "                                                   \"Tweet\",\n",
    "                                                   \"Hashtags\",\n",
    "                                                   \"Conversation_Id\",\n",
    "                                                   \"In_reply_To\",\n",
    "                                                   \"Coordinates\",\n",
    "                                                   \"Place\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4bd0643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/jvx2qhjd0dg8ckghthtxhwgw0000gn/T/ipykernel_40533/3907763601.py:21: FutureWarning: content is deprecated, use rawContent instead\n",
      "  tweet.content,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Date_Created</th>\n",
       "      <th>Follows_Count</th>\n",
       "      <th>Friends_Count</th>\n",
       "      <th>Retweet_Count</th>\n",
       "      <th>Language</th>\n",
       "      <th>Date_Tweet</th>\n",
       "      <th>Number_of_Likes</th>\n",
       "      <th>Source_of_Tweet</th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Conversation_Id</th>\n",
       "      <th>In_reply_To</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSUSUofT</td>\n",
       "      <td>2016-10-05 20:54:39+00:00</td>\n",
       "      <td>313</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-15 04:17:42+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1592371236038119424</td>\n",
       "      <td>Hey #UofT community, there is still time to re...</td>\n",
       "      <td>[UofT]</td>\n",
       "      <td>1592371236038119424</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EquityPubPolicy</td>\n",
       "      <td>2014-07-16 15:29:10+00:00</td>\n",
       "      <td>767</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-15 00:15:27+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1592310271426826240</td>\n",
       "      <td>We are so excited to commence this year's sess...</td>\n",
       "      <td>[EDPPtalks, UofT, topoli, onpoli, cdnpoli, mun...</td>\n",
       "      <td>1592310271426826240</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uoftalumni</td>\n",
       "      <td>2009-03-10 15:27:10+00:00</td>\n",
       "      <td>7214</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-14 22:25:10+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>1592282519021420552</td>\n",
       "      <td>Community members gathered on #UofTâ€™s three ca...</td>\n",
       "      <td>[UofT, UofTalumni]</td>\n",
       "      <td>1592282519021420552</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uoftlibraries</td>\n",
       "      <td>2009-10-03 18:10:17+00:00</td>\n",
       "      <td>11003</td>\n",
       "      <td>758</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-14 21:43:52+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1592272128136871936</td>\n",
       "      <td>Our Robarts Library book display for both Nove...</td>\n",
       "      <td>[UofT]</td>\n",
       "      <td>1592272128136871936</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UTMBiology</td>\n",
       "      <td>2012-12-05 18:41:31+00:00</td>\n",
       "      <td>2202</td>\n",
       "      <td>2260</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-14 21:03:25+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Zoho Social</td>\n",
       "      <td>1592261946170306564</td>\n",
       "      <td>You can't miss this Friday, Nov 18, #UTMBiolog...</td>\n",
       "      <td>[UTMBiology, UofT]</td>\n",
       "      <td>1592261946170306564</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UTLaw</td>\n",
       "      <td>2009-01-12 14:56:57+00:00</td>\n",
       "      <td>15338</td>\n",
       "      <td>1878</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-11 18:01:25+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>1591128981843083266</td>\n",
       "      <td>This Monday!\\n\\nJoin Prof. @BedardRubin @NDesR...</td>\n",
       "      <td>[UofT]</td>\n",
       "      <td>1591128981843083266</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UofTStudentLife</td>\n",
       "      <td>2010-04-07 16:44:11+00:00</td>\n",
       "      <td>20246</td>\n",
       "      <td>633</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-11 18:00:14+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Sprout Social</td>\n",
       "      <td>1591128683862949915</td>\n",
       "      <td>Explore how spiritual well-being and mental he...</td>\n",
       "      <td>[uoft]</td>\n",
       "      <td>1591128683862949915</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>uoftlibraries</td>\n",
       "      <td>2009-10-03 18:10:17+00:00</td>\n",
       "      <td>11003</td>\n",
       "      <td>758</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-11 17:53:39+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1591127025972285440</td>\n",
       "      <td>#UofT libraries was honoured to place a wreath...</td>\n",
       "      <td>[UofT, LestWeForget, RemembranceDay]</td>\n",
       "      <td>1591127025972285440</td>\n",
       "      <td>None</td>\n",
       "      <td>Coordinates(longitude=-79.639319, latitude=43....</td>\n",
       "      <td>Place(fullName='Toronto, Ontario', name='Toron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CentreToronto</td>\n",
       "      <td>2018-12-04 15:16:48+00:00</td>\n",
       "      <td>31</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>zh</td>\n",
       "      <td>2022-11-11 17:31:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1591121495128170496</td>\n",
       "      <td>å­¦ä¹ ç­–ç•¥å’ŒæŠ€èƒ½æ¥æ”¹å–„æ‚¨çš„ #MentalHealth å¹¶æ›´å¥½åœ°åº”å¯¹å­¦ç”Ÿç”Ÿæ´»çš„æŒ‘æˆ˜ï¼ æˆ‘ä»¬ä¸ºå­¦...</td>\n",
       "      <td>[MentalHealth, CBT, Markham, Toronto, UofT, Yo...</td>\n",
       "      <td>1591121495128170496</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>IMIUofT</td>\n",
       "      <td>2013-11-06 20:43:04+00:00</td>\n",
       "      <td>1681</td>\n",
       "      <td>304</td>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-11-11 17:07:13+00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1591115341719310336</td>\n",
       "      <td>\"Memory matters.\" - @UTM Principal Alex Gilles...</td>\n",
       "      <td>[RemembranceDay, LestWeForget, uoft]</td>\n",
       "      <td>1591115341719310336</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                User              Date_Created  Follows_Count  Friends_Count  \\\n",
       "0           CSUSUofT 2016-10-05 20:54:39+00:00            313            394   \n",
       "1    EquityPubPolicy 2014-07-16 15:29:10+00:00            767            309   \n",
       "2         uoftalumni 2009-03-10 15:27:10+00:00           7214           1310   \n",
       "3      uoftlibraries 2009-10-03 18:10:17+00:00          11003            758   \n",
       "4         UTMBiology 2012-12-05 18:41:31+00:00           2202           2260   \n",
       "..               ...                       ...            ...            ...   \n",
       "96             UTLaw 2009-01-12 14:56:57+00:00          15338           1878   \n",
       "97   UofTStudentLife 2010-04-07 16:44:11+00:00          20246            633   \n",
       "98     uoftlibraries 2009-10-03 18:10:17+00:00          11003            758   \n",
       "99     CentreToronto 2018-12-04 15:16:48+00:00             31            174   \n",
       "100          IMIUofT 2013-11-06 20:43:04+00:00           1681            304   \n",
       "\n",
       "     Retweet_Count Language                Date_Tweet  Number_of_Likes  \\\n",
       "0                0       en 2022-11-15 04:17:42+00:00                0   \n",
       "1                0       en 2022-11-15 00:15:27+00:00                0   \n",
       "2                0       en 2022-11-14 22:25:10+00:00                1   \n",
       "3                0       en 2022-11-14 21:43:52+00:00                2   \n",
       "4                0       en 2022-11-14 21:03:25+00:00                1   \n",
       "..             ...      ...                       ...              ...   \n",
       "96               0       en 2022-11-11 18:01:25+00:00                1   \n",
       "97               0       en 2022-11-11 18:00:14+00:00                1   \n",
       "98               5       en 2022-11-11 17:53:39+00:00               11   \n",
       "99               0       zh 2022-11-11 17:31:40+00:00                0   \n",
       "100              4       en 2022-11-11 17:07:13+00:00               16   \n",
       "\n",
       "        Source_of_Tweet             Tweet_Id  \\\n",
       "0       Twitter Web App  1592371236038119424   \n",
       "1       Twitter Web App  1592310271426826240   \n",
       "2        Hootsuite Inc.  1592282519021420552   \n",
       "3       Twitter Web App  1592272128136871936   \n",
       "4           Zoho Social  1592261946170306564   \n",
       "..                  ...                  ...   \n",
       "96       Hootsuite Inc.  1591128981843083266   \n",
       "97        Sprout Social  1591128683862949915   \n",
       "98   Twitter for iPhone  1591127025972285440   \n",
       "99      Twitter Web App  1591121495128170496   \n",
       "100     Twitter Web App  1591115341719310336   \n",
       "\n",
       "                                                 Tweet  \\\n",
       "0    Hey #UofT community, there is still time to re...   \n",
       "1    We are so excited to commence this year's sess...   \n",
       "2    Community members gathered on #UofTâ€™s three ca...   \n",
       "3    Our Robarts Library book display for both Nove...   \n",
       "4    You can't miss this Friday, Nov 18, #UTMBiolog...   \n",
       "..                                                 ...   \n",
       "96   This Monday!\\n\\nJoin Prof. @BedardRubin @NDesR...   \n",
       "97   Explore how spiritual well-being and mental he...   \n",
       "98   #UofT libraries was honoured to place a wreath...   \n",
       "99   å­¦ä¹ ç­–ç•¥å’ŒæŠ€èƒ½æ¥æ”¹å–„æ‚¨çš„ #MentalHealth å¹¶æ›´å¥½åœ°åº”å¯¹å­¦ç”Ÿç”Ÿæ´»çš„æŒ‘æˆ˜ï¼ æˆ‘ä»¬ä¸ºå­¦...   \n",
       "100  \"Memory matters.\" - @UTM Principal Alex Gilles...   \n",
       "\n",
       "                                              Hashtags      Conversation_Id  \\\n",
       "0                                               [UofT]  1592371236038119424   \n",
       "1    [EDPPtalks, UofT, topoli, onpoli, cdnpoli, mun...  1592310271426826240   \n",
       "2                                   [UofT, UofTalumni]  1592282519021420552   \n",
       "3                                               [UofT]  1592272128136871936   \n",
       "4                                   [UTMBiology, UofT]  1592261946170306564   \n",
       "..                                                 ...                  ...   \n",
       "96                                              [UofT]  1591128981843083266   \n",
       "97                                              [uoft]  1591128683862949915   \n",
       "98                [UofT, LestWeForget, RemembranceDay]  1591127025972285440   \n",
       "99   [MentalHealth, CBT, Markham, Toronto, UofT, Yo...  1591121495128170496   \n",
       "100               [RemembranceDay, LestWeForget, uoft]  1591115341719310336   \n",
       "\n",
       "    In_reply_To                                        Coordinates  \\\n",
       "0          None                                               None   \n",
       "1          None                                               None   \n",
       "2          None                                               None   \n",
       "3          None                                               None   \n",
       "4          None                                               None   \n",
       "..          ...                                                ...   \n",
       "96         None                                               None   \n",
       "97         None                                               None   \n",
       "98         None  Coordinates(longitude=-79.639319, latitude=43....   \n",
       "99         None                                               None   \n",
       "100        None                                               None   \n",
       "\n",
       "                                                 Place  \n",
       "0                                                 None  \n",
       "1                                                 None  \n",
       "2                                                 None  \n",
       "3                                                 None  \n",
       "4                                                 None  \n",
       "..                                                 ...  \n",
       "96                                                None  \n",
       "97                                                None  \n",
       "98   Place(fullName='Toronto, Ontario', name='Toron...  \n",
       "99                                                None  \n",
       "100                                               None  \n",
       "\n",
       "[101 rows x 16 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uoft_df2 = tweet_scraper('#uoft', 100)\n",
    "uoft_df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
